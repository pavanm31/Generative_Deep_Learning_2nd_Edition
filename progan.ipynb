{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNE3fmL8LtJpqA/uohJcwUL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pavanm31/Generative_Deep_Learning_2nd_Edition/blob/main/progan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mtcnn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-T8vLrvL2fwx",
        "outputId": "b91ca467-64f4-49a7-88a7-667ebea2a439"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mtcnn in /usr/local/lib/python3.10/dist-packages (0.1.1)\n",
            "Requirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from mtcnn) (2.15.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from mtcnn) (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python>=4.1.0->mtcnn) (1.25.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V35nPUMd2Rb9"
      },
      "outputs": [],
      "source": [
        "from math import sqrt\n",
        "from numpy import load, asarray, zeros, ones, savez_compressed\n",
        "from numpy.random import randn, randint\n",
        "from skimage.transform import resize\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Reshape, Conv2D\n",
        "from tensorflow.keras.layers import UpSampling2D, AveragePooling2D, LeakyReLU, Layer, Add\n",
        "from keras.constraints import max_norm\n",
        "from keras.initializers import RandomNormal\n",
        "import mtcnn\n",
        "from mtcnn.mtcnn import MTCNN\n",
        "from keras import backend\n",
        "from matplotlib import pyplot\n",
        "from tensorflow.keras.models import load_model\n",
        "import cv2\n",
        "import os\n",
        "from os import listdir\n",
        "from PIL import Image\n",
        "import zipfile\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the image file\n",
        "def load_image(filename):\n",
        "    image = Image.open(filename)\n",
        "    image = image.convert('RGB')\n",
        "    pixels = asarray(image)\n",
        "    return pixels\n",
        "\n",
        "# extract the face from a loaded image and resize\n",
        "def extract_face(model, pixels, required_size=(128, 128)):\n",
        "    # detect face in the image\n",
        "    faces = model.detect_faces(pixels)\n",
        "    if len(faces) == 0:\n",
        "        return None\n",
        "\n",
        "    # extract details of the face\n",
        "    x1, y1, width, height = faces[0]['box']\n",
        "    x1, y1 = abs(x1), abs(y1)\n",
        "\n",
        "    x2, y2 = x1 + width, y1 + height\n",
        "    face_pixels = pixels[y1:y2, x1:x2]\n",
        "    image = Image.fromarray(face_pixels)\n",
        "    image = image.resize(required_size)\n",
        "    face_array = asarray(image)\n",
        "\n",
        "    return face_array\n",
        "\n",
        "# load images and extract faces for all images in a directory\n",
        "def load_faces(directory, n_faces):\n",
        "    # prepare model\n",
        "    model = MTCNN()\n",
        "    faces = list()\n",
        "\n",
        "    for filename in os.listdir(directory):\n",
        "        # Computing the retrieval and extraction of faces\n",
        "        pixels = load_image(directory + filename)\n",
        "        face = extract_face(model, pixels)\n",
        "        if face is None:\n",
        "            continue\n",
        "        faces.append(face)\n",
        "        print(len(faces), face.shape)\n",
        "        if len(faces) >= n_faces:\n",
        "            break\n",
        "\n",
        "    return asarray(faces)"
      ],
      "metadata": {
        "id": "-QLJ5kUK6nt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!pip install zipfile\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# ... (rest of your code)\n",
        "\n",
        "zip_file_path = '/content/img_align_celeba.zip'  # Path to your zip file\n",
        "extracted_dir = '/content/img_align_celeba'  # Directory to extract to\n",
        "\n",
        "# Verify if the file exists and is a zip file\n",
        "if not os.path.exists(zip_file_path):\n",
        "    print(f\"Error: File not found at {zip_file_path}\")\n",
        "else:\n",
        "    try:\n",
        "        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "            # Check if it's a valid zip file before extracting\n",
        "            if zip_ref.testzip() is None:\n",
        "                zip_ref.extractall(extracted_dir)\n",
        "                print(\"File extracted successfully!\")\n",
        "            else:\n",
        "                print(\"Error: The zip file appears to be corrupted.\")\n",
        "    except zipfile.BadZipFile:\n",
        "        print(\"Error: The file is not a valid zip file.\")\n",
        "\n",
        "# Now use the extracted directory\n",
        "directory = extracted_dir\n",
        "all_faces = load_faces(directory, 20000)\n",
        "print('Loaded: ', all_faces.shape)\n",
        "\n",
        "# save in compressed format\n",
        "savez_compressed('img_align_celeba_128.npz', all_faces)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1Ns7DK58WE0",
        "outputId": "10fbe5d4-82bd-4428-c09c-8170de7bc53c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement zipfile (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for zipfile\u001b[0m\u001b[31m\n",
            "\u001b[0mError: The file is not a valid zip file.\n",
            "Loaded:  (0,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the prepared dataset\n",
        "from numpy import load\n",
        "data = load('img_align_celeba_128.npz')\n",
        "faces = data['arr_0']\n",
        "print('Loaded: ', faces.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTZCWNIC9FUO",
        "outputId": "27e76139-c598-47d6-abd3-2067bbe2cb47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded:  (0,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pixel-wise feature vector normalization layer\n",
        "class PixelNormalization(Layer):\n",
        "    # initialize the layer\n",
        "    def __init__(self, **kwargs):\n",
        "        super(PixelNormalization, self).__init__(**kwargs)\n",
        "\n",
        "    # perform the operation\n",
        "    def call(self, inputs):\n",
        "        # computing pixel values\n",
        "        values = inputs**2.0\n",
        "        mean_values = backend.mean(values, axis=-1, keepdims=True)\n",
        "        mean_values += 1.0e-8\n",
        "        l2 = backend.sqrt(mean_values)\n",
        "        normalized = inputs / l2\n",
        "        return normalized\n",
        "\n",
        "    # define the output shape of the layer\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape"
      ],
      "metadata": {
        "id": "Xhewh3769JJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mini-batch standard deviation layer\n",
        "class MinibatchStdev(Layer):\n",
        "    # initialize the layer\n",
        "    def __init__(self, **kwargs):\n",
        "        super(MinibatchStdev, self).__init__(**kwargs)\n",
        "\n",
        "    # perform the operation\n",
        "    def call(self, inputs):\n",
        "        mean = backend.mean(inputs, axis=0, keepdims=True)\n",
        "        squ_diffs = backend.square(inputs - mean)\n",
        "        mean_sq_diff = backend.mean(squ_diffs, axis=0, keepdims=True)\n",
        "        mean_sq_diff += 1e-8\n",
        "        stdev = backend.sqrt(mean_sq_diff)\n",
        "\n",
        "        mean_pix = backend.mean(stdev, keepdims=True)\n",
        "        shape = backend.shape(inputs)\n",
        "        output = backend.tile(mean_pix, (shape[0], shape[1], shape[2], 1))\n",
        "\n",
        "        combined = backend.concatenate([inputs, output], axis=-1)\n",
        "        return combined\n",
        "\n",
        "    # define the output shape of the layer\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        input_shape = list(input_shape)\n",
        "        input_shape[-1] += 1\n",
        "        return tuple(input_shape)"
      ],
      "metadata": {
        "id": "CB7mUbYt9RKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# weighted sum output\n",
        "class WeightedSum(Add):\n",
        "    # init with default value\n",
        "    def __init__(self, alpha=0.0, **kwargs):\n",
        "        super(WeightedSum, self).__init__(**kwargs)\n",
        "        self.alpha = backend.variable(alpha, name='ws_alpha')\n",
        "\n",
        "    # output a weighted sum of inputs\n",
        "    def _merge_function(self, inputs):\n",
        "        # only supports a weighted sum of two inputs\n",
        "        assert (len(inputs) == 2)\n",
        "        # ((1-a) * input1) + (a * input2)\n",
        "        output = ((1.0 - self.alpha) * inputs[0]) + (self.alpha * inputs[1])\n",
        "        return output\n",
        "\n",
        "# calculate wasserstein loss\n",
        "def wasserstein_loss(y_true, y_pred):\n",
        "    return backend.mean(y_true * y_pred)"
      ],
      "metadata": {
        "id": "yNc3CPm-9Yng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "def load_real_samples(filename):\n",
        "    data = load(filename)\n",
        "    X = data['arr_0']\n",
        "    X = X.astype('float32')\n",
        "    X = (X - 127.5) / 127.5\n",
        "    return X\n",
        "\n",
        "# select real samples\n",
        "def generate_real_samples(dataset, n_samples):\n",
        "    ix = randint(0, dataset.shape[0], n_samples)\n",
        "    X = dataset[ix]\n",
        "    y = ones((n_samples, 1))\n",
        "    return X, y\n",
        "\n",
        "# generate points in latent space as input for the generator\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "    x_input = randn(latent_dim * n_samples)\n",
        "    x_input = x_input.reshape(n_samples, latent_dim)\n",
        "    return x_input\n",
        "\n",
        "# use the generator to generate n fake examples, with class labels\n",
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "    x_input = generate_latent_points(latent_dim, n_samples)\n",
        "    X = generator.predict(x_input)\n",
        "    y = -ones((n_samples, 1))\n",
        "    return X, y\n",
        "\n",
        "# update the alpha value on each instance of WeightedSum\n",
        "def update_fadein(models, step, n_steps):\n",
        "    alpha = step / float(n_steps - 1)\n",
        "    for model in models:\n",
        "        for layer in model.layers:\n",
        "            if isinstance(layer, WeightedSum):\n",
        "                backend.set_value(layer.alpha, alpha)\n",
        "\n",
        "# scale images to preferred size\n",
        "def scale_dataset(images, new_shape):\n",
        "    images_list = list()\n",
        "    for image in images:\n",
        "        new_image = resize(image, new_shape, 0)\n",
        "        images_list.append(new_image)\n",
        "    return asarray(images_list)"
      ],
      "metadata": {
        "id": "DNph0GGI9b1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adding a generator block\n",
        "def add_generator_block(old_model):\n",
        "    init = RandomNormal(stddev=0.02)\n",
        "    const = max_norm(1.0)\n",
        "    block_end = old_model.layers[-2].output\n",
        "\n",
        "    # upsample, and define new block\n",
        "    upsampling = UpSampling2D()(block_end)\n",
        "    g = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(upsampling)\n",
        "    g = PixelNormalization()(g)\n",
        "    g = LeakyReLU(alpha=0.2)(g)\n",
        "    g = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(g)\n",
        "    g = PixelNormalization()(g)\n",
        "    g = LeakyReLU(alpha=0.2)(g)\n",
        "\n",
        "    out_image = Conv2D(3, (1,1), padding='same', kernel_initializer=init, kernel_constraint=const)(g)\n",
        "    model1 = Model(old_model.input, out_image)\n",
        "    out_old = old_model.layers[-1]\n",
        "    out_image2 = out_old(upsampling)\n",
        "\n",
        "    merged = WeightedSum()([out_image2, out_image])\n",
        "    model2 = Model(old_model.input, merged)\n",
        "    return [model1, model2]"
      ],
      "metadata": {
        "id": "zV5xfl6O9k0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define generator models\n",
        "def define_generator(latent_dim, n_blocks, in_dim=4):\n",
        "    init = RandomNormal(stddev=0.02)\n",
        "    const = max_norm(1.0)\n",
        "    model_list = list()\n",
        "    in_latent = Input(shape=(latent_dim,))\n",
        "    g  = Dense(128 * in_dim * in_dim, kernel_initializer=init, kernel_constraint=const)(in_latent)\n",
        "    g = Reshape((in_dim, in_dim, 128))(g)\n",
        "\n",
        "    # conv 4x4, input block\n",
        "    g = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(g)\n",
        "    g = PixelNormalization()(g)\n",
        "    g = LeakyReLU(alpha=0.2)(g)\n",
        "\n",
        "    # conv 3x3\n",
        "    g = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(g)\n",
        "    g = PixelNormalization()(g)\n",
        "    g = LeakyReLU(alpha=0.2)(g)\n",
        "\n",
        "    # conv 1x1, output block\n",
        "    out_image = Conv2D(3, (1,1), padding='same', kernel_initializer=init, kernel_constraint=const)(g)\n",
        "    model = Model(in_latent, out_image)\n",
        "    model_list.append([model, model])\n",
        "\n",
        "    for i in range(1, n_blocks):\n",
        "        old_model = model_list[i - 1][0]\n",
        "        models = add_generator_block(old_model)\n",
        "        model_list.append(models)\n",
        "\n",
        "    return model_list"
      ],
      "metadata": {
        "id": "8d-bkaLM9l3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adding a discriminator block\n",
        "def add_discriminator_block(old_model, n_input_layers=3):\n",
        "    init = RandomNormal(stddev=0.02)\n",
        "    const = max_norm(1.0)\n",
        "    in_shape = list(old_model.input.shape)\n",
        "\n",
        "    # define new input shape as double the size\n",
        "    input_shape = (in_shape[-2]*2, in_shape[-2]*2, in_shape[-1])\n",
        "    in_image = Input(shape=input_shape)\n",
        "\n",
        "    # define new input processing layer\n",
        "    d = Conv2D(128, (1,1), padding='same', kernel_initializer=init, kernel_constraint=const)(in_image)\n",
        "    d = LeakyReLU(alpha=0.2)(d)\n",
        "\n",
        "    # define new block\n",
        "    d = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(d)\n",
        "    d = LeakyReLU(alpha=0.2)(d)\n",
        "    d = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(d)\n",
        "    d = LeakyReLU(alpha=0.2)(d)\n",
        "    d = AveragePooling2D()(d)\n",
        "    block_new = d\n",
        "\n",
        "    # skip the input, 1x1 and activation for the old model\n",
        "    for i in range(n_input_layers, len(old_model.layers)):\n",
        "        d = old_model.layers[i](d)\n",
        "    model1 = Model(in_image, d)\n",
        "\n",
        "    model1.compile(loss=wasserstein_loss, optimizer=Adam(lr=0.001, beta_1=0, beta_2=0.99, epsilon=10e-8))\n",
        "\n",
        "    downsample = AveragePooling2D()(in_image)\n",
        "\n",
        "    block_old = old_model.layers[1](downsample)\n",
        "    block_old = old_model.layers[2](block_old)\n",
        "    d = WeightedSum()([block_old, block_new])\n",
        "\n",
        "    for i in range(n_input_layers, len(old_model.layers)):\n",
        "        d = old_model.layers[i](d)\n",
        "\n",
        "    model2 = Model(in_image, d)\n",
        "\n",
        "    model2.compile(loss=wasserstein_loss, optimizer=Adam(lr=0.001, beta_1=0, beta_2=0.99, epsilon=10e-8))\n",
        "    return [model1, model2]"
      ],
      "metadata": {
        "id": "Bs4tKCmI9qTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the discriminator models for each image resolution\n",
        "def define_discriminator(n_blocks, input_shape=(4,4,3)):\n",
        "    init = RandomNormal(stddev=0.02)\n",
        "    const = max_norm(1.0)\n",
        "    model_list = list()\n",
        "    in_image = Input(shape=input_shape)\n",
        "\n",
        "    d = Conv2D(128, (1,1), padding='same', kernel_initializer=init, kernel_constraint=const)(in_image)\n",
        "    d = LeakyReLU(alpha=0.2)(d)\n",
        "    d = MinibatchStdev()(d)\n",
        "\n",
        "    d = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(d)\n",
        "    d = LeakyReLU(alpha=0.2)(d)\n",
        "    d = Conv2D(128, (4,4), padding='same', kernel_initializer=init, kernel_constraint=const)(d)\n",
        "    d = LeakyReLU(alpha=0.2)(d)\n",
        "\n",
        "    d = Flatten()(d)\n",
        "    out_class = Dense(1)(d)\n",
        "\n",
        "    model = Model(in_image, out_class)\n",
        "    model.compile(loss=wasserstein_loss, optimizer=Adam(lr=0.001, beta_1=0, beta_2=0.99, epsilon=10e-8))\n",
        "    model_list.append([model, model])\n",
        "\n",
        "    for i in range(1, n_blocks):\n",
        "        old_model = model_list[i - 1][0]\n",
        "        models = add_discriminator_block(old_model)\n",
        "        model_list.append(models)\n",
        "\n",
        "    return model_list"
      ],
      "metadata": {
        "id": "Nvt6Yx5t9t_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define composite models for training generators via discriminators\n",
        "\n",
        "def define_composite(discriminators, generators):\n",
        "    model_list = list()\n",
        "    # create composite models\n",
        "    for i in range(len(discriminators)):\n",
        "        g_models, d_models = generators[i], discriminators[i]\n",
        "        # straight-through model\n",
        "        d_models[0].trainable = False\n",
        "        model1 = Sequential()\n",
        "        model1.add(g_models[0])\n",
        "        model1.add(d_models[0])\n",
        "        model1.compile(loss=wasserstein_loss, optimizer=Adam(lr=0.001, beta_1=0, beta_2=0.99, epsilon=10e-8))\n",
        "        # fade-in model\n",
        "        d_models[1].trainable = False\n",
        "        model2 = Sequential()\n",
        "        model2.add(g_models[1])\n",
        "        model2.add(d_models[1])\n",
        "        model2.compile(loss=wasserstein_loss, optimizer=Adam(lr=0.001, beta_1=0, beta_2=0.99, epsilon=10e-8))\n",
        "        # store\n",
        "        model_list.append([model1, model2])\n",
        "    return model_list"
      ],
      "metadata": {
        "id": "lQgkPLbS925O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train a generator and discriminator\n",
        "def train_epochs(g_model, d_model, gan_model, dataset, n_epochs, n_batch, fadein=False):\n",
        "    bat_per_epo = int(dataset.shape[0] / n_batch)\n",
        "    n_steps = bat_per_epo * n_epochs\n",
        "    half_batch = int(n_batch / 2)\n",
        "\n",
        "    for i in range(n_steps):\n",
        "        # update alpha for all WeightedSum layers when fading in new blocks\n",
        "        if fadein:\n",
        "            update_fadein([g_model, d_model, gan_model], i, n_steps)\n",
        "        # prepare real and fake samples\n",
        "        X_real, y_real = generate_real_samples(dataset, half_batch)\n",
        "        X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
        "\n",
        "        # update discriminator model\n",
        "        d_loss1 = d_model.train_on_batch(X_real, y_real)\n",
        "        d_loss2 = d_model.train_on_batch(X_fake, y_fake)\n",
        "\n",
        "        # update the generator via the discriminator's error\n",
        "        z_input = generate_latent_points(latent_dim, n_batch)\n",
        "        y_real2 = ones((n_batch, 1))\n",
        "        g_loss = gan_model.train_on_batch(z_input, y_real2)\n",
        "\n",
        "        # summarize loss on this batch\n",
        "        print('>%d, d1=%.3f, d2=%.3f g=%.3f' % (i+1, d_loss1, d_loss2, g_loss))\n",
        "\n",
        "# train the generator and discriminator\n",
        "def train(g_models, d_models, gan_models, dataset, latent_dim, e_norm, e_fadein, n_batch):\n",
        "    g_normal, d_normal, gan_normal = g_models[0][0], d_models[0][0], gan_models[0][0]\n",
        "    gen_shape = g_normal.output_shape\n",
        "    scaled_data = scale_dataset(dataset, gen_shape[1:])\n",
        "    print('Scaled Data', scaled_data.shape)\n",
        "\n",
        "    # train normal or straight-through models\n",
        "    train_epochs(g_normal, d_normal, gan_normal, scaled_data, e_norm[0], n_batch[0])\n",
        "    summarize_performance('tuned', g_normal, latent_dim)\n",
        "\n",
        "    # process each level of growth\n",
        "    for i in range(1, len(g_models)):\n",
        "        # retrieve models for this level of growth\n",
        "        [g_normal, g_fadein] = g_models[i]\n",
        "        [d_normal, d_fadein] = d_models[i]\n",
        "        [gan_normal, gan_fadein] = gan_models[i]\n",
        "\n",
        "        # scale dataset to appropriate size\n",
        "        gen_shape = g_normal.output_shape\n",
        "        scaled_data = scale_dataset(dataset, gen_shape[1:])\n",
        "        print('Scaled Data', scaled_data.shape)\n",
        "\n",
        "        # train fade-in models for next level of growth\n",
        "        train_epochs(g_fadein, d_fadein, gan_fadein, scaled_data, e_fadein[i], n_batch[i], True)\n",
        "        summarize_performance('faded', g_fadein, latent_dim)\n",
        "\n",
        "        # train normal or straight-through models\n",
        "        train_epochs(g_normal, d_normal, gan_normal, scaled_data, e_norm[i], n_batch[i])\n",
        "        summarize_performance('tuned', g_normal, latent_dim)"
      ],
      "metadata": {
        "id": "aDZiFHul96VV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate samples and save as a plot and save the model\n",
        "def summarize_performance(status, g_model, latent_dim, n_samples=25):\n",
        "    gen_shape = g_model.output_shape\n",
        "    name = '%03dx%03d-%s' % (gen_shape[1], gen_shape[2], status)\n",
        "\n",
        "    X, _ = generate_fake_samples(g_model, latent_dim, n_samples)\n",
        "    X = (X - X.min()) / (X.max() - X.min())\n",
        "\n",
        "    square = int(sqrt(n_samples))\n",
        "    for i in range(n_samples):\n",
        "        pyplot.subplot(square, square, 1 + i)\n",
        "        pyplot.axis('off')\n",
        "        pyplot.imshow(X[i])\n",
        "\n",
        "    # save plot to file\n",
        "    filename1 = 'plot_%s.png' % (name)\n",
        "    pyplot.savefig(filename1)\n",
        "    pyplot.close()\n",
        "\n",
        "    filename2 = 'model_%s.h5' % (name)\n",
        "    g_model.save(filename2)\n",
        "    print('>Saved: %s and %s' % (filename1, filename2))"
      ],
      "metadata": {
        "id": "lNNfAqC197-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# number of growth phases where 6 blocks == [4, 8, 16, 32, 64, 128]\n",
        "n_blocks = 6\n",
        "latent_dim = 100\n",
        "\n",
        "d_models = define_discriminator(n_blocks)\n",
        "g_models = define_generator(latent_dim, n_blocks)\n",
        "gan_models = define_composite(d_models, g_models)\n",
        "\n",
        "dataset = load_real_samples('/content/img_align_celeba_128.npz')\n",
        "print('Loaded', dataset.shape)\n",
        "\n",
        "n_batch = [16, 16, 16, 8, 4, 4]\n",
        "n_epochs = [5, 8, 8, 10, 10, 10]\n",
        "\n",
        "train(g_models, d_models, gan_models, dataset, latent_dim, n_epochs, n_epochs, n_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DDYKY37-CMR",
        "outputId": "ffbdd187-caca-4bf9-a432-5e004b268c3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded (0,)\n",
            "Scaled Data (0,)\n",
            "1/1 [==============================] - 0s 205ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">Saved: plot_004x004-tuned.png and model_004x004-tuned.h5\n",
            "Scaled Data (0,)\n",
            "1/1 [==============================] - 0s 311ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">Saved: plot_008x008-faded.png and model_008x008-faded.h5\n",
            "1/1 [==============================] - 0s 260ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">Saved: plot_008x008-tuned.png and model_008x008-tuned.h5\n",
            "Scaled Data (0,)\n",
            "1/1 [==============================] - 0s 386ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">Saved: plot_016x016-faded.png and model_016x016-faded.h5\n",
            "1/1 [==============================] - 0s 303ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">Saved: plot_016x016-tuned.png and model_016x016-tuned.h5\n",
            "Scaled Data (0,)\n",
            "1/1 [==============================] - 1s 679ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">Saved: plot_032x032-faded.png and model_032x032-faded.h5\n",
            "1/1 [==============================] - 1s 577ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">Saved: plot_032x032-tuned.png and model_032x032-tuned.h5\n",
            "Scaled Data (0,)\n",
            "1/1 [==============================] - 2s 2s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">Saved: plot_064x064-faded.png and model_064x064-faded.h5\n",
            "1/1 [==============================] - 2s 2s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">Saved: plot_064x064-tuned.png and model_064x064-tuned.h5\n",
            "Scaled Data (0,)\n",
            "1/1 [==============================] - 7s 7s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">Saved: plot_128x128-faded.png and model_128x128-faded.h5\n",
            "1/1 [==============================] - 7s 7s/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">Saved: plot_128x128-tuned.png and model_128x128-tuned.h5\n"
          ]
        }
      ]
    }
  ]
}